{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "federal-filing",
   "metadata": {},
   "source": [
    "# instrument2\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Execute the code blocks below in order. The headers of each cell explains what the corresponding code does. A full explanation is available in jupyter.md.\n",
    "\n",
    "## Reference\n",
    "\n",
    "* https://www.tensorflow.org/lite/microcontrollers/get_started\n",
    "* https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb\n",
    "* https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech/train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-drove",
   "metadata": {},
   "source": [
    "## Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "explicit-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: pandas in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from matplotlib) (8.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.25.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# install Python modules\n",
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-space",
   "metadata": {},
   "source": [
    "# Configure defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "under-municipality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training these words: yes,no\n",
      "Training steps in each stage: 12000,3000\n",
      "Learning rate in each stage: 0.001,0.0001\n",
      "Total number of training steps: 15000\n"
     ]
    }
   ],
   "source": [
    "# A comma-delimited list of the words you want to train for.\n",
    "# The options are: yes,no,up,down,left,right,on,off,stop,go\n",
    "# All the other words will be used to train an \"unknown\" label and silent\n",
    "# audio data with no spoken words will be used to train a \"silence\" label.\n",
    "WANTED_WORDS = \"yes,no\"\n",
    "\n",
    "# The number of steps and learning rates can be specified as comma-separated\n",
    "# lists to define the rate at each stage. For example,\n",
    "# TRAINING_STEPS=12000,3000 and LEARNING_RATE=0.001,0.0001\n",
    "# will run 12,000 training loops in total, with a rate of 0.001 for the first\n",
    "# 8,000, and 0.0001 for the final 3,000.\n",
    "TRAINING_STEPS = \"12000,3000\"\n",
    "LEARNING_RATE = \"0.001,0.0001\"\n",
    "\n",
    "# Calculate the total number of steps, which is used to identify the checkpoint\n",
    "# file name.\n",
    "TOTAL_STEPS = str(sum(map(lambda string: int(string), TRAINING_STEPS.split(\",\"))))\n",
    "\n",
    "# Print the configuration to confirm it\n",
    "print(\"Training these words: %s\" % WANTED_WORDS)\n",
    "print(\"Training steps in each stage: %s\" % TRAINING_STEPS)\n",
    "print(\"Learning rate in each stage: %s\" % LEARNING_RATE)\n",
    "print(\"Total number of training steps: %s\" % TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "precise-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of 'silence' and 'unknown' training samples required\n",
    "# to ensure that we have equal number of samples for each label.\n",
    "number_of_labels = WANTED_WORDS.count(',') + 1\n",
    "number_of_total_labels = number_of_labels + 2 # for 'silence' and 'unknown' label\n",
    "equal_percentage_of_training_samples = int(100.0/(number_of_total_labels))\n",
    "SILENT_PERCENTAGE = equal_percentage_of_training_samples\n",
    "UNKNOWN_PERCENTAGE = equal_percentage_of_training_samples\n",
    "\n",
    "# Constants which are shared during training and inference\n",
    "PREPROCESS = 'micro'\n",
    "WINDOW_STRIDE = 20\n",
    "MODEL_ARCHITECTURE = 'tiny_conv' # Other options include: single_fc, conv,\n",
    "                      # low_latency_conv, low_latency_svdf, tiny_embedding_conv\n",
    "\n",
    "# Constants used during training only\n",
    "VERBOSITY = 'WARN'\n",
    "EVAL_STEP_INTERVAL = '1000'\n",
    "SAVE_STEP_INTERVAL = '1000'\n",
    "\n",
    "# Constants for training directories and filepaths\n",
    "DATASET_DIR =  'dataset/'\n",
    "LOGS_DIR = 'logs/'\n",
    "TRAIN_DIR = 'train/' # for training checkpoints and other files.\n",
    "\n",
    "# Constants for inference directories and filepaths\n",
    "import os\n",
    "MODELS_DIR = 'models'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "  os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = os.path.join(MODELS_DIR, 'model.pb')\n",
    "MODEL_TFLITE = os.path.join(MODELS_DIR, 'model.tflite')\n",
    "FLOAT_MODEL_TFLITE = os.path.join(MODELS_DIR, 'float_model.tflite')\n",
    "MODEL_TFLITE_MICRO = os.path.join(MODELS_DIR, 'model.cc')\n",
    "SAVED_MODEL = os.path.join(MODELS_DIR, 'saved_model')\n",
    "\n",
    "QUANT_INPUT_MIN = 0.0\n",
    "QUANT_INPUT_MAX = 26.0\n",
    "QUANT_INPUT_RANGE = QUANT_INPUT_MAX - QUANT_INPUT_MIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-wallpaper",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "answering-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'tensorflow' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# delete old data from previous runs\n",
    "!rm -rf {DATASET_DIR} {LOGS_DIR} {TRAIN_DIR} {MODELS_DIR}\n",
    "\n",
    "# clone the TensorFlow Github Repository\n",
    "# which contains the relevant code required to run this tutorial\n",
    "!git clone -q --depth 1 https://github.com/tensorflow/tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-message",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interested-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-25 11:54:00.574303: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      ">> Downloading speech_commands_v0.02.tar.gz 100.0%mmands_v0.02.tar.gz 42.1%ommands_v0.02.tar.gz 43.5%ommands_v0.02.tar.gz 45.5%ommands_v0.02.tar.gz 57.4%ommands_v0.02.tar.gz 58.0%ommands_v0.02.tar.gz 58.5%ommands_v0.02.tar.gz 59.5%5%ommands_v0.02.tar.gz 59.5%ommands_v0.02.tar.gz 59.7%ommands_v0.02.tar.gz 59.8%ommands_v0.02.tar.gz 59.8%ommands_v0.02.tar.gz 61.7%ommands_v0.02.tar.gz 62.3%ommands_v0.02.tar.gz 62.3%ommands_v0.02.tar.gz 62.4%ommands_v0.02.tar.gz 62.5%ommands_v0.02.tar.gz 63.0%ommands_v0.02.tar.gz 63.1%ommands_v0.02.tar.gz 63.1%3.2%ommands_v0.02.tar.gz 63.3%3%ommands_v0.02.tar.gz 63.4%ommands_v0.02.tar.gz 64.1%ommands_v0.02.tar.gz 69.2%ommands_v0.02.tar.gz 69.3%ommands_v0.02.tar.gz 73.7%ommands_v0.02.tar.gz 77.3%ommands_v0.02.tar.gz 92.3%ommands_v0.02.tar.gz 92.3%ommands_v0.02.tar.gz 92.6%ommands_v0.02.tar.gz 93.1%ommands_v0.02.tar.gz 93.5%ommands_v0.02.tar.gz 93.7%0%_commands_v0.02.tar.gz 97.0%\n",
      "2021-02-25 12:00:16.897265: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-02-25 12:00:16.931381: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2021-02-25 12:00:44.152009: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at whole_file_read_ops.cc:116 : Not found: dataset/no/15c563d7_nohash_2.wav; No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1359, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1451, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: dataset/no/15c563d7_nohash_2.wav; No such file or directory\n",
      "\t [[{{node data/ReadFile}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"tensorflow/tensorflow/examples/speech_commands/train.py\", line 513, in <module>\n",
      "    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"tensorflow/tensorflow/examples/speech_commands/train.py\", line 235, in main\n",
      "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/instruments/instrument2/tensorflow/tensorflow/examples/speech_commands/input_data.py\", line 604, in get_data\n",
      "    summary, data_tensor = sess.run(\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1368, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1394, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: dataset/no/15c563d7_nohash_2.wav; No such file or directory\n",
      "\t [[node data/ReadFile (defined at /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/instruments/instrument2/tensorflow/tensorflow/examples/speech_commands/input_data.py:399) ]]\n",
      "\n",
      "Errors may have originated from an input operation.\n",
      "Input Source operations connected to node data/ReadFile:\n",
      " data/wav_filename (defined at /Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/instruments/instrument2/tensorflow/tensorflow/examples/speech_commands/input_data.py:397)\n",
      "\n",
      "Original stack trace for 'data/ReadFile':\n",
      "  File \"tensorflow/tensorflow/examples/speech_commands/train.py\", line 513, in <module>\n",
      "    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"tensorflow/tensorflow/examples/speech_commands/train.py\", line 102, in main\n",
      "    audio_processor = input_data.AudioProcessor(\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/instruments/instrument2/tensorflow/tensorflow/examples/speech_commands/input_data.py\", line 203, in __init__\n",
      "    self.prepare_processing_graph(model_settings, summaries_dir)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/instruments/instrument2/tensorflow/tensorflow/examples/speech_commands/input_data.py\", line 399, in prepare_processing_graph\n",
      "    wav_loader = io_ops.read_file(self.wav_filename_placeholder_)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 571, in read_file\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 748, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3528, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1990, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python tensorflow/tensorflow/examples/speech_commands/train.py \\\n",
    "--data_dir={DATASET_DIR} \\\n",
    "--wanted_words={WANTED_WORDS} \\\n",
    "--silence_percentage={SILENT_PERCENTAGE} \\\n",
    "--unknown_percentage={UNKNOWN_PERCENTAGE} \\\n",
    "--preprocess={PREPROCESS} \\\n",
    "--window_stride={WINDOW_STRIDE} \\\n",
    "--model_architecture={MODEL_ARCHITECTURE} \\\n",
    "--how_many_training_steps={TRAINING_STEPS} \\\n",
    "--learning_rate={LEARNING_RATE} \\\n",
    "--train_dir={TRAIN_DIR} \\\n",
    "--summaries_dir={LOGS_DIR} \\\n",
    "--verbosity={VERBOSITY} \\\n",
    "--eval_step_interval={EVAL_STEP_INTERVAL} \\\n",
    "--save_step_interval={SAVE_STEP_INTERVAL}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-speed",
   "metadata": {},
   "source": [
    "## Generate a TensorFlow Model for inference\n",
    "\n",
    "Combine relevant training results (graph, weights, etc) into a single file for inference.\n",
    "\n",
    "This process is known as freezing a model and the resulting model is known as a frozen model/graph, as it cannot be further re-trained after this process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "atmospheric-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-25 12:00:54.797900: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"tensorflow/tensorflow/examples/speech_commands/freeze.py\", line 312, in <module>\n",
      "    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"tensorflow/tensorflow/examples/speech_commands/freeze.py\", line 231, in main\n",
      "    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/instruments/instrument2/tensorflow/tensorflow/examples/speech_commands/models.py\", line 161, in load_variables_from_checkpoint\n",
      "    saver.restore(sess, start_checkpoint)\n",
      "  File \"/Users/montoyamoraga/github/montoyamoraga/tiny-trainable-instruments/env/lib/python3.8/site-packages/tensorflow/python/training/saver.py\", line 1289, in restore\n",
      "    raise ValueError(\"The passed save_path is not a valid checkpoint: \" +\n",
      "ValueError: The passed save_path is not a valid checkpoint: train/tiny_conv.ckpt-15000\n"
     ]
    }
   ],
   "source": [
    "!rm -rf {SAVED_MODEL}\n",
    "!python tensorflow/tensorflow/examples/speech_commands/freeze.py \\\n",
    "--wanted_words=$WANTED_WORDS \\\n",
    "--window_stride_ms=$WINDOW_STRIDE \\\n",
    "--preprocess=$PREPROCESS \\\n",
    "--model_architecture=$MODEL_ARCHITECTURE \\\n",
    "--start_checkpoint=$TRAIN_DIR$MODEL_ARCHITECTURE'.ckpt-'{TOTAL_STEPS} \\\n",
    "--save_format=saved_model \\\n",
    "--output_file={SAVED_MODEL}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-million",
   "metadata": {},
   "source": [
    "## Generate a TensorFlow Lite Model\n",
    "\n",
    "Convert the frozen graph into a TensorFlow Lite model, which is fully quantized for use with embedded devices.\n",
    "\n",
    "The following cell will also print the model size, which will be under 20 kilobytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "satellite-disposal",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'input_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c465e0fa631d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# We add this path so we can import the speech processing modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/tensorflow/tensorflow/examples/speech_commands/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'input_data'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# We add this path so we can import the speech processing modules.\n",
    "sys.path.append(\"/content/tensorflow/tensorflow/examples/speech_commands/\")\n",
    "import input_data\n",
    "import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-eating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-coating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-certification",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
