{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "under-player",
   "metadata": {},
   "source": [
    "# instrument1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-breakdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "* https://www.tensorflow.org/lite/microcontrollers/get_started\n",
    "* https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-dining",
   "metadata": {},
   "source": [
    "## Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version from colab\n",
    "# !apt-get -qq install xxd\n",
    "\n",
    "# TODO: how to install xxd with python or how to replace it\n",
    "\n",
    "#######\n",
    "\n",
    "# version from colab: \n",
    "# !pip install tensorflow pandas numpy matplotlib\n",
    "\n",
    "# following recommendations from\n",
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-accent",
   "metadata": {},
   "source": [
    "## Upload data\n",
    "\n",
    "* This Jupyter notebook lives right next to a folder called data\n",
    "* The data lives in the files gesture0.csv, gesture1.csv, and gesture2.csv\n",
    "* For generating your own data and replacing these files, use the sketch inst1_collecting_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-china",
   "metadata": {},
   "source": [
    "## Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Python modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# list of filenames\n",
    "filenames = [\"gesture0.csv\", \"gesture1.csv\", \"gesture2.csv\"]\n",
    "\n",
    "# create list of readings with pandas\n",
    "df = list()\n",
    "for i in range(len(filenames)):\n",
    "    df.append(pd.read_csv(\"./data/\" + filenames[i]))\n",
    "\n",
    "# create list of indices\n",
    "indices = list()\n",
    "for i in range(len(df)):\n",
    "    indices.append(range(1, len(df[i]['aX']) + 1))\n",
    "    \n",
    "# TODO: what does this line do?\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# plot acceleration and gyroscope data for each file\n",
    "for i in range(len(df)):\n",
    "    plt.plot(indices[i], df[i]['aX'], 'g.', label='x', linestyle='solid', marker=',')\n",
    "    plt.plot(indices[i], df[i]['aY'], 'b.', label='y', linestyle='solid', marker=',')\n",
    "    plt.plot(indices[i], df[i]['aZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
    "    plt.title(\"acceleration \" + filenames[i])\n",
    "    plt.xlabel(\"sample number\")\n",
    "    plt.ylabel(\"acceleration (G)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(indices[i], df[i]['gX'], 'g.', label='x', linestyle='solid', marker=',')\n",
    "    plt.plot(indices[i], df[i]['gY'], 'b.', label='y', linestyle='solid', marker=',')\n",
    "    plt.plot(indices[i], df[i]['gZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
    "    plt.title(\"gyroscope \" + filenames[i])\n",
    "    plt.xlabel(\"sample number\")\n",
    "    plt.ylabel(\"gyroscope (deg/sec)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-diagram",
   "metadata": {},
   "source": [
    "## Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# print TensorFlow version\n",
    "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
    "\n",
    "# set a seed the pseudo-random numbers\n",
    "# with a seed we get the same pseudo-random numbers each time\n",
    "seed = 12345\n",
    "# apply the seed to numpy and tensorflow\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# list of gestures in the data\n",
    "GESTURES = [\n",
    "    \"gesture0\",\n",
    "    \"gesture1\",\n",
    "    \"gesture2\"\n",
    "]\n",
    "\n",
    "# retrieve number of gestures from list\n",
    "NUM_GESTURES = len(GESTURES)\n",
    "\n",
    "# number of samples per gesture in each .csv file\n",
    "SAMPLES_PER_GESTURE = 119\n",
    "\n",
    "# create a one-hot encoded matrix that is used in the output\n",
    "# np.eye is an identity matrix, all zeroes but the diagonal\n",
    "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
    "\n",
    "# initialize lists for inputs and outputs\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# read each csv file and push an input and output\n",
    "for gesture_index in range(NUM_GESTURES):\n",
    "    \n",
    "    # retrieve current gesture\n",
    "    gesture = GESTURES[gesture_index]\n",
    "    \n",
    "    # print status message\n",
    "    print(f\"current index {gesture_index} for gesture '{gesture}'\")\n",
    "    \n",
    "    # retrieve output\n",
    "    output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
    "    \n",
    "    # read from corresponding csv file\n",
    "    df = pd.read_csv(\"./data/\" + gesture + \".csv\")\n",
    "    \n",
    "    # calculate the number of gesture recordings in the file\n",
    "    num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
    "    \n",
    "    # prints status message\n",
    "    print(f\"\\t{num_recordings} recordings in {gesture}\")\n",
    "    \n",
    "    # go through every recording\n",
    "    for i in range(num_recordings):\n",
    "        \n",
    "        # new list for tensor\n",
    "        tensor = []\n",
    "        \n",
    "        # go through every sample\n",
    "        for j in range(SAMPLES_PER_GESTURE):\n",
    "            \n",
    "            # retrieve index\n",
    "            index = i * SAMPLES_PER_GESTURE + j\n",
    "            \n",
    "            # normalize the input data, to float numbers between 0 to 1\n",
    "            \n",
    "            # acceleration current range is -4 to +4\n",
    "            # so it needs to be offset by 4 and divided by 8\n",
    "            aOffset = 4\n",
    "            aDivisor = 8\n",
    "            \n",
    "            # gyroscope current range is -2000 to +2000\n",
    "            # so it needs to be offset by 2000 and divided by 4000\n",
    "            gOffset = 2000\n",
    "            gDivisor = 4000\n",
    "            \n",
    "            # build tensor with normalized data\n",
    "            tensor += [\n",
    "                (df['aX'][index] + aOffset) / aDivisor,\n",
    "                (df['aY'][index] + aOffset) / aDivisor,\n",
    "                (df['aZ'][index] + aOffset) / aDivisor,\n",
    "                (df['gX'][index] + gOffset) / gDivisor,\n",
    "                (df['gY'][index] + gOffset) / gDivisor,\n",
    "                (df['gZ'][index] + gOffset) / gDivisor\n",
    "            ]\n",
    "            \n",
    "            # append the tensor to the inputs list\n",
    "            inputs.append(tensor)\n",
    "            \n",
    "            # append the output to the outputs list\n",
    "            outputs.append(output)\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)\n",
    "\n",
    "print(\"parsing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-cathedral",
   "metadata": {},
   "source": [
    "## Randomize and split the input and output pairs for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split input and output pairs into sets of data:\n",
    "# 60% for training, 20% for validation, and 20% for testing\n",
    "\n",
    "# randomize the order of the inputs,\n",
    "# so they can be evenly distributed\n",
    "# for training, testing, and validation\n",
    "# https://stackoverflow.com/a/37710486/2020087\n",
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# swap the consecutive indexes\n",
    "# (0, 1, 2, etc) with the randomized indexes\n",
    "inputs = inputs[randomize]\n",
    "outputs = outputs[randomize]\n",
    "\n",
    "# split the recordings (group of samples) into three sets:\n",
    "# training, testing and validation\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "print(\"data set randomization and splitting complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-bulgarian",
   "metadata": {},
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model and train it\n",
    "\n",
    "# model variable for a sequential\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu')) # relu is used for performance\n",
    "\n",
    "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(inputs_train, outputs_train, epochs=600, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-snake",
   "metadata": {},
   "source": [
    "## Graph the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the size of the graphs. The default size is (6,4).\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(plt.rcParams[\"figure.figsize\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-timothy",
   "metadata": {},
   "source": [
    "## Graph the loss again, skipping a bit of the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the loss again skipping a bit of the start\n",
    "SKIP = 100\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-conjunction",
   "metadata": {},
   "source": [
    "## Graph the mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of mean absolute error\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-glucose",
   "metadata": {},
   "source": [
    "## Run with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(inputs_test)\n",
    "\n",
    "# print the predictions and the expected ouputs\n",
    "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
    "print(\"actual =\\n\", outputs_test)\n",
    "\n",
    "# Plot the predictions along with to the test data\n",
    "\n",
    "# TODO: this line crashes, i dont know why\n",
    "# plt.clf()\n",
    "\n",
    "\n",
    "# plt.title('Training data predicted vs actual values')\n",
    "# plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
    "# plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-childhood",
   "metadata": {},
   "source": [
    "## Convert the trained model to TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "import os\n",
    "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-literacy",
   "metadata": {},
   "source": [
    "## Encode the model in a header file for Arduino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"const unsigned char model[] = {\" > ./data/model.h\n",
    "!cat gesture_model.tflite | xxd -i      >> ./data/model.h\n",
    "!echo \"};\"                              >> ./data/model.h\n",
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"./data/model.h\")\n",
    "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
    "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}