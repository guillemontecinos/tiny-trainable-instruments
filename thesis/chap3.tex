\chapter{Early experiments}

\section{Microcontrollers}

My first exposure to Arduino was as an undergraduate student of electrical engineering back home in Chile. The Arduino Uno was a very powerful device, and I saw its applications to arts, when with a friend we created a rudimentary automatic tuner for guitar, that performed pitch detection and then controlled a motor to move the tuning machine on the guitar to achieve the desired tuning, with a PID controller.

I didn't use it too much, because they were relatively hard to obtain, and I was more interested in software at the time.

Fast forward to 2015, I became a graduate student at New York University's Interactive Telecommunications Program, where on my first semester I took the amazing class Introduction to Physical Computing, with one of Arduino's co-creators Tom Igoe.

While freelancing in New York, I was introduced to an Arduino off-shoot, the Teensy, which captivated me by its USB MIDI capabilities, which allowed for standalone operation without a host computer, and by its audio library, which allowed me to create interactive standalone experiences, triggering samples and applying audio effects on device.

While at MIT Media Lab, I was delighted by the newer versions of Teensy, which are even faster and more powerful, and which led me to start designing handheld samplers for field recordings.

This in turn led me to review the current NYU ITP materials for physical computing, where they currently stopped using the now classic Arduino Uno, and have incorporated 


\section{Machine learning}

My first experiment with creative machine learning, was with my NYU ITP classmate Corbin Ordel, who was a student at Gene Kogan's machine learning class, and we teamed up to hack a project we called Piano Die Hard, built with Wekinator, KNN algorithm, some Max MSP and openFrameworks apps, and an Arduino microcontroller. We created a video database of explosions in the Die Hard movie franchise, and another one of other 1980's movies with no explosions, and we trained our machine learning algorithm to distinguish between the categories explosion and no explosion. We featured this project at a NYU ITP show, were written up at the Daily Beast newspaper, and exhibited our work at the alt-ai conference.

In 2017, while I was finishing my appointment as research resident at NYU ITP, Crist√≥bal Valenzuela had started the project RunwayML as his master's thesis, and also I saw the first experiments with deeplearn.js, later TensorFlow.js, which soon became the foundation of the ml5.js library, built at NYU ITP.

I decided I wanted to dip my toes in machine learning, so I took a month-long intensive class at the School of Machines in Berlin, Germany, facilitated by Gene Kogan and Andreas Refsgaard, and organized by Rachel Uwa.



Machine learning for artists


ml5.js is a wrapper for Tensorflow.js, NYU ITP. Browser based

Runway ML by Alejandro Matamala, Anastasis Germanidis, and Cris Valenzuela.

Casey Reas' book for GANs.
